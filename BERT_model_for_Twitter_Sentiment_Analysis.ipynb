{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dUpvvHyopgmw"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "#from plotly import tools\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "import re\n",
        "import string\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import dataset urdu dataset\n",
        "data = pd.read_csv('Tweets.csv')\n",
        "data.head()"
      ],
      "metadata": {
        "id": "UBXHWerTp2pN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "AUNhwYA2qTmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "xUYliwWrqm5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji"
      ],
      "metadata": {
        "id": "ALx1FvmXqin-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import emoji\n",
        "\n",
        "def clean_text(text):\n",
        "    # Ensure text is a string\n",
        "    text = str(text)\n",
        "\n",
        "    # Removal of hashtags, HTML tags, mentions, punctuations, and URLs\n",
        "    text = re.sub(r'#\\w+', '', text)             # Remove hashtags\n",
        "    text = re.sub(r'<.*?>', '', text)            # Remove HTML tags\n",
        "    text = re.sub(r'@[A-Za-z0-9_]+', '', text)   # Remove mentions numbers\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)          # Remove punctuations\n",
        "    text = re.sub(r'http\\S+', '', text)          # Remove URLs\n",
        "    text = re.sub(r'(.)\\1+', r'\\1', text)          # Remove repeating charactersz\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)            # remove words containing numbers\n",
        "    # Changing to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Replace emoji with corresponding text representation\n",
        "    text = emoji.demojize(text)\n",
        "\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "yrUjCYZMqYYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['text']= data['text'].apply(lambda x: clean_text(x))\n",
        "data['text'].head(10)"
      ],
      "metadata": {
        "id": "L-38_GA-qgvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Visulization"
      ],
      "metadata": {
        "id": "c5W-BH-Nv0Aj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot sentiment distribution as a pie chart\n",
        "plt.figure(figsize=(8, 6))\n",
        "data['sentiment'].value_counts().plot(kind='pie', autopct='%1.1f%%', colors=['skyblue', 'lightgreen', 'lightcoral'])\n",
        "plt.title('Distribution of Sentiments in Tweets')\n",
        "plt.ylabel('')  # Hide the y-axis label\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1n2b050Dt7C3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Plot sentiment distribution as a bar chart\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x='sentiment', data=data, palette='pastel')\n",
        "plt.title('Distribution of Sentiments in Tweets')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Sa0vRDtwup-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "# Initialize a subplot grid\n",
        "fig, axes = plt.subplots(nrows=1, ncols=len(data['sentiment'].unique()), figsize=(15, 5))\n",
        "\n",
        "# Iterate over unique sentiment categories\n",
        "for i, sentiment in enumerate(data['sentiment'].unique()):\n",
        "    subset = data[data['sentiment'] == sentiment]\n",
        "    text = \" \".join(subset['text'].tolist())\n",
        "\n",
        "    # Generate word cloud\n",
        "    wordcloud = WordCloud(width=400, height=200, background_color='white').generate(text)\n",
        "\n",
        "    # Plot word cloud in the corresponding subplot\n",
        "    axes[i].imshow(wordcloud, interpolation='bilinear')\n",
        "    axes[i].set_title(f'Most Common Words in {sentiment.capitalize()} Tweets')\n",
        "    axes[i].axis(\"off\")\n",
        "\n",
        "# Adjust layout and display plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HCjaojziuzfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT Implementation"
      ],
      "metadata": {
        "id": "aGT-8GvXw7tQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from transformers import AdamW\n"
      ],
      "metadata": {
        "id": "kf0FqzW5yHUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Create a LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit the LabelEncoder on the 'sentiment' column\n",
        "data['encoded_sentiment'] = label_encoder.fit_transform(data['sentiment'])\n",
        "\n",
        "# Checking encoding\n",
        "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "print(label_mapping)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "CK7f6W9K0CqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# select the X with text and y with target class\n",
        "X = data['text']\n",
        "y = data['encoded_sentiment']"
      ],
      "metadata": {
        "id": "4p7-e40W0fbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (70/30 ratio with stratified sampling)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42,stratify=data['encoded_sentiment'])"
      ],
      "metadata": {
        "id": "wFzMK9i41MJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained BERT model and tokenizer\n",
        "model_name = 'bert-base-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=3)  # Assuming binary classification"
      ],
      "metadata": {
        "id": "lpLtOi6pw_Jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize and preprocess the training data\n",
        "train_inputs = tokenizer(list(X_train), padding=True, truncation=True, return_tensors='pt', max_length=128)\n",
        "train_labels = torch.tensor(list(y_train))\n",
        "\n",
        "# Tokenize and preprocess the testing data\n",
        "test_inputs = tokenizer(list(X_test), padding=True, truncation=True, return_tensors='pt', max_length=128)\n",
        "test_labels = torch.tensor(list(y_test))"
      ],
      "metadata": {
        "id": "UWK9Pw8EzB_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune the BERT model\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "epochs = 3\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(**train_inputs, labels=train_labels)\n",
        "    loss = outputs.loss\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(**test_inputs)\n",
        "    logits = outputs.logits\n",
        "    predictions = torch.argmax(logits, dim=1)\n",
        "    y_pred = predictions.numpy()"
      ],
      "metadata": {
        "id": "L2A_mzyMyxyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change target_names based on your class labels\n",
        "target_names = ['negative 0', 'neutral 1', 'positive 2']\n",
        "\n",
        "# Generate and print the classification report\n",
        "report = classification_report(test_labels.numpy(), y_pred, digits=4, target_names=target_names)\n",
        "print(report)"
      ],
      "metadata": {
        "id": "VPaJCljJyx2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "buzrLQQ-2V6B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}